using System;
using System.Collections.Generic;
using System.Text;
using System.Text.RegularExpressions;

namespace Flame.DSharp.Lexer
{
    #region TokenParser

    /// <summary>
    /// TokenParser
    /// </summary>
    /// <remarks>
    /// TokenParser is the main parser engine for converting input into lexical tokens.
    /// </remarks>
    public class TokenParser : ITokenStream
    {
        private Dictionary<TokenType, string> _tokens;
        private Dictionary<TokenType, MatchCollection> _regExMatchCollection;
        private string _inputString;
        private string _sourceIdentifier;
        private int _index;

        /// <summary>
        /// InputString Property
        /// </summary>
        /// <value>
        /// The string value that holds the input string.
        /// </value>
        public string InputString
        {
        	const get
        	{
        		return _inputString;
        	}
            set
            {
                _inputString = value;
                PrepareRegex();
            }
        }
        
        private void SetupParser()
        {
        	_tokens = new Dictionary<TokenType, string>();
            _regExMatchCollection = new Dictionary<TokenType, MatchCollection>();
            _index = 0;
            _inputString = "";

            _tokens.Add(TokenType.Semicolon, ";");
            _tokens.Add(TokenType.ColonColon, "::");
            _tokens.Add(TokenType.Colon, ":");
            _tokens.Add(TokenType.String, "\"([^\"\\\\]|\\\\.)*\"");
            _tokens.Add(TokenType.Char, "\\'([^\\'\\\\]|\\\\.)*\\'");
            _tokens.Add(TokenType.Float32, "[0-9]*\\.+[0-9]+([eE][+-]?[0-9]+)?[Ff]");
            _tokens.Add(TokenType.Float64, "[0-9]*\\.+[0-9]+([eE][+-]?[0-9]+)?");
            _tokens.Add(TokenType.HexInteger, "0x[a-fA-F0-9]+");
            _tokens.Add(TokenType.BinaryInteger, "0b[0-1]+");
            _tokens.Add(TokenType.FalseLiteral, "\\bfalse\\b");
            _tokens.Add(TokenType.TrueLiteral, "\\btrue\\b");
            _tokens.Add(TokenType.UsingKeyword, "\\busing\\b");
            _tokens.Add(TokenType.VarKeyword, "\\bvar\\b");
            _tokens.Add(TokenType.SetKeyword, "\\bset\\b");
            _tokens.Add(TokenType.IsKeyword, "\\bis\\b");
            _tokens.Add(TokenType.AsKeyword, "\\bas\\b");
            _tokens.Add(TokenType.IfKeyword, "\\bif\\b");
            _tokens.Add(TokenType.ElseKeyword, "\\belse\\b");
            _tokens.Add(TokenType.WhileKeyword, "\\bwhile\\b");
            _tokens.Add(TokenType.WhereKeyword, "\\bwhere\\b");
            _tokens.Add(TokenType.SizeOfKeyword, "\\bsizeof\\b");
            _tokens.Add(TokenType.ForeachKeyword, "\\bforeach\\b");
            _tokens.Add(TokenType.ForKeyword, "\\bfor\\b");
            _tokens.Add(TokenType.ReturnKeyword, "\\breturn\\b");
            _tokens.Add(TokenType.NewKeyword, "\\bnew\\b");
            _tokens.Add(TokenType.TryKeyword, "\\btry\\b");
            _tokens.Add(TokenType.CatchKeyword, "\\bcatch\\b");
            _tokens.Add(TokenType.FinallyKeyword, "\\bfinally\\b");
            _tokens.Add(TokenType.DefaultKeyword, "\\bdefault\\b");
            _tokens.Add(TokenType.NamespaceKeyword, "\\bnamespace\\b");
            _tokens.Add(TokenType.ClassKeyword, "\\bclass\\b");
            _tokens.Add(TokenType.StructKeyword, "\\bstruct\\b");
            _tokens.Add(TokenType.InterfaceKeyword, "\\binterface\\b");
            _tokens.Add(TokenType.EnumKeyword, "\\benum\\b");
            _tokens.Add(TokenType.PublicKeyword, "\\bpublic\\b");
            _tokens.Add(TokenType.ProtectedKeyword, "\\bprotected\\b");
            _tokens.Add(TokenType.AssemblyKeyword, "\\bassembly\\b");
            _tokens.Add(TokenType.PrivateKeyword, "\\bprivate\\b");
            _tokens.Add(TokenType.AbstractKeyword, "\\babstract\\b");
            _tokens.Add(TokenType.VirtualKeyword, "\\bvirtual\\b");
            _tokens.Add(TokenType.OverrideKeyword, "\\boverride\\b");
            _tokens.Add(TokenType.SealedKeyword, "\\bsealed\\b");
            _tokens.Add(TokenType.InlineKeyword, "\\binline\\b");
            _tokens.Add(TokenType.ConstKeyword, "\\bconst\\b");
            _tokens.Add(TokenType.StaticKeyword, "\\bstatic\\b");
            _tokens.Add(TokenType.ThisKeyword, "\\bthis\\b");
            _tokens.Add(TokenType.BaseKeyword, "\\bbase\\b");
            _tokens.Add(TokenType.InKeyword, "\\bin\\b");
            _tokens.Add(TokenType.OutKeyword, "\\bout\\b");
            _tokens.Add(TokenType.NullKeyword, "\\bnull\\b");
            _tokens.Add(TokenType.BreakKeyword, "\\bbreak\\b");
            _tokens.Add(TokenType.NextKeyword, "\\bnext\\b");
            _tokens.Add(TokenType.DoKeyword, "\\bdo\\b");
            _tokens.Add(TokenType.Identifier, "[a-zA-Z_][a-zA-Z0-9_]*");
            _tokens.Add(TokenType.Whitespace, "[ \\t\\r\\n]+");
            _tokens.Add(TokenType.Integer, "[0-9]+");
            _tokens.Add(TokenType.RArrow, "\\->");
            _tokens.Add(TokenType.Dot, "\\.");
            _tokens.Add(TokenType.RParen, "\\(");
            _tokens.Add(TokenType.LParen, "\\)");
            _tokens.Add(TokenType.RBrackets, "\\[");
            _tokens.Add(TokenType.LBrackets, "\\]");
            _tokens.Add(TokenType.RBraces, "{");
            _tokens.Add(TokenType.LBraces, "}");
            _tokens.Add(TokenType.Comma, ",");
            _tokens.Add(TokenType.AndAnd, "&&");
            _tokens.Add(TokenType.AndEquals, "&=");
            _tokens.Add(TokenType.And, "&");
            _tokens.Add(TokenType.BarBar, "\\|\\|");
            _tokens.Add(TokenType.BarEquals, "\\|=");
            _tokens.Add(TokenType.Bar, "\\|");
            _tokens.Add(TokenType.PercentEquals, "%=");
            _tokens.Add(TokenType.Percent, "%");
            _tokens.Add(TokenType.CaretEquals, "\\^=");
            _tokens.Add(TokenType.Caret, "\\^");
            _tokens.Add(TokenType.TildeEquals, "~=");
            _tokens.Add(TokenType.Tilde, "~");
            _tokens.Add(TokenType.NotEquals, "!=");
            _tokens.Add(TokenType.Not, "!");
            _tokens.Add(TokenType.EqualsEquals, "==");
            //_tokens.Add(TokenType.RightShift, ">>"); // KEEP THIS COMMENTED OUT!
            _tokens.Add(TokenType.GreaterThanOrEquals, ">=");
            _tokens.Add(TokenType.GreaterThan, ">");
            _tokens.Add(TokenType.LeftShift, "<<");
            _tokens.Add(TokenType.LessThanOrEquals, "<=");
            _tokens.Add(TokenType.LessThan, "<");
            _tokens.Add(TokenType.Equals, "=");
            _tokens.Add(TokenType.PlusPlus, "\\+\\+");
            _tokens.Add(TokenType.PlusEquals, "\\+=");
            _tokens.Add(TokenType.Plus, "\\+");
            _tokens.Add(TokenType.MinusMinus, "\\-\\-");
            _tokens.Add(TokenType.MinusEquals, "\\-=");
            _tokens.Add(TokenType.Minus, "\\-");
            _tokens.Add(TokenType.AsteriskEquals, "\\*=");
            _tokens.Add(TokenType.Asterisk, "\\*");
            _tokens.Add(TokenType.DescriptionComment, "///.*\\n?");
            _tokens.Add(TokenType.LineComment, "//.*\\n?");
            _tokens.Add(TokenType.BigComment, "/\\*(.|\\n)*?\\*/");
            _tokens.Add(TokenType.PreprocessorDirective, "#.*\\n?");
            _tokens.Add(TokenType.SlashEquals, "/=");
            _tokens.Add(TokenType.Slash, "/");
        }

        /// <summary>
        /// Default Constructor
        /// </summary>
        /// <remarks>
        /// The constructor initalizes memory and adds all of the tokens to the token dictionary.
        /// </remarks>
        public const this()
        {
			SetupParser();
        }

        /// <summary>
        /// Calls the default constructor and sets up an input string.
        /// </summary>
        /// <remarks>
        /// The constructor initalizes memory and adds all of the tokens to the token dictionary.
        /// </remarks>
        public const this(string InputString)
        {
        	SetupParser();
        	this.InputString = InputString;
        }

        /// <summary>
        /// PrepareRegex prepares the regex for parsing by pre-matching the Regex tokens.
        /// </summary>
        private void PrepareRegex()
        {
            _regExMatchCollection.Clear();
            foreach (KeyValuePair<TokenType, string> pair in _tokens)
            {
                _regExMatchCollection.Add(pair.Key, Regex.Matches(_inputString, pair.Value));
            }
        }

        /// <summary>
        /// ResetParser resets the parser to its inital state. Reloading InputString is required.
        /// </summary>
        /// <seealso cref="InputString" />
        public void ResetParser()
        {
            _index = 0;
            _inputString = "";
            _regExMatchCollection.Clear();
        }

        public void Reset()
        {
            string input = _inputString;
            ResetParser();
            this.InputString = input;
        }

        /// <summary>
        /// GetToken gets the next token in queue
        /// </summary>
        /// <remarks>
        /// GetToken attempts to the match the next character(s) using the
        /// Regex rules defined in the dictionary. If a match can not be
        /// located, then an Undefined token will be created with an empty
        /// string value. In addition, the token pointer will be incremented
        /// by one so that this token doesn't attempt to get identified again by
        /// GetToken()
        /// </remarks>
        public Token Next()
        {
            if (_index >= _inputString.Length)
                return Token.EndOfFile;

            foreach (KeyValuePair<TokenType, MatchCollection> pair in _regExMatchCollection)
            {
                foreach (Match match in pair.Value)
                {
                    if (match.Index == _index)
                    {
                        _index += match.Length;
                        return new Token(pair.Key, match.Value, match.Index);
                    }

                    if (match.Index > _index)
                    {
                        break;
                    }
                }
            }
            ++_index;
            return new Token(TokenType.UNDEFINED, "");
        }

        /// <summary>
        /// Returns the next token after the provided position
        /// </summary>
        public const PeekToken Peek(TokenIdentifier Position)
        {
            int oldIndex = _index;

            _index = Position.Identifier;

            if (_index >= _inputString.Length)
            {
                _index = oldIndex;
                return PeekToken.EndOfFile;
            }

            foreach (KeyValuePair<TokenType, string> pair in _tokens)
            {
                Regex r = new Regex(pair.Value);
                Match m = r.Match(_inputString, _index);

                if (m.Success && m.Index == _index)
                {
                    _index += m.Length;
                    PeekToken pt = new PeekToken(_index, new Token(pair.Key, m.Value, _index));
                    _index = oldIndex;
                    return pt;
                }
            }
            PeekToken pt2 = new PeekToken(_index + 1, new Token(TokenType.UNDEFINED, "", _index + 1));
            _index = oldIndex;
            return pt2;
        }

        public TokenIdentifier CurrentPosition : ITokenStream.CurrentPosition
        {
            const get
            {
                return new TokenIdentifier(_index);
            }
        }

        public void Seek(TokenIdentifier Position)
        {
            _index = Position.Identifier;
        }
    }

    #endregion
}